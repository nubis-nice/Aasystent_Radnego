import { createRequire } from "node:module";
import { Readable } from "node:stream";
import { getSTTClient, getLLMClient, getAIConfig } from "../ai/index.js";
const require = createRequire(import.meta.url);
const { toFile } = require("openai");
const AUDIO_MIME_TYPES = [
    "audio/mpeg",
    "audio/mp3",
    "audio/wav",
    "audio/wave",
    "audio/x-wav",
    "audio/ogg",
    "audio/x-m4a",
    "audio/m4a",
    "audio/flac",
    "audio/aac",
];
const VIDEO_MIME_TYPES = [
    "video/mp4",
    "video/webm",
    "video/x-matroska",
    "video/avi",
    "video/quicktime",
];
export class AudioTranscriber {
    sttClient = null;
    llmClient = null;
    sttModel = "whisper-1";
    llmModel = "gpt-4o";
    constructor() { }
    /**
     * Inicjalizacja z konfiguracjÄ… uÅ¼ytkownika przez AIClientFactory
     */
    async initializeWithUserConfig(userId) {
        // Pobierz klienta STT (Speech-to-Text) z fabryki
        this.sttClient = await getSTTClient(userId);
        // Pobierz konfiguracjÄ™ STT aby znaÄ‡ model
        const sttConfig = await getAIConfig(userId, "stt");
        this.sttModel = sttConfig.modelName;
        // Pobierz klienta LLM do analizy transkryptu
        this.llmClient = await getLLMClient(userId);
        // Pobierz konfiguracjÄ™ LLM aby znaÄ‡ model
        const llmConfig = await getAIConfig(userId, "llm");
        this.llmModel = llmConfig.modelName;
        console.log(`[AudioTranscriber] Initialized for user ${userId.substring(0, 8)}...`);
        console.log(`[AudioTranscriber] STT: provider=${sttConfig.provider}, model=${this.sttModel}`);
        console.log(`[AudioTranscriber] LLM: model=${this.llmModel}`);
    }
    isAudioOrVideo(mimeType) {
        return (AUDIO_MIME_TYPES.includes(mimeType) || VIDEO_MIME_TYPES.includes(mimeType));
    }
    async transcribe(fileBuffer, fileName, mimeType) {
        const fileSize = fileBuffer.length;
        const maxSize = 25 * 1024 * 1024; // 25MB - Whisper limit
        if (fileSize > maxSize) {
            return {
                success: false,
                rawTranscript: "",
                segments: [],
                summary: {
                    averageTension: 0,
                    dominantSentiment: "neutral",
                    overallCredibility: 0,
                    overallCredibilityEmoji: "ğŸ”´",
                    speakerCount: 0,
                    duration: "0:00",
                },
                metadata: {
                    fileName,
                    fileType: this.getFileType(mimeType),
                    mimeType,
                    fileSize,
                    language: "pl",
                },
                formattedTranscript: "",
                error: `Plik jest zbyt duÅ¼y (${Math.round(fileSize / 1024 / 1024)}MB). Maksymalny rozmiar to 25MB.`,
            };
        }
        if (!this.sttClient) {
            throw new Error("STT client not initialized. Call initializeWithUserConfig first.");
        }
        try {
            console.log(`[AudioTranscriber] Transcribing: ${fileName} (${mimeType})`);
            // Step 1: Transcribe with Whisper
            const rawTranscript = await this.whisperTranscribe(fileBuffer, fileName);
            if (!rawTranscript || rawTranscript.trim().length === 0) {
                return {
                    success: false,
                    rawTranscript: "",
                    segments: [],
                    summary: {
                        averageTension: 0,
                        dominantSentiment: "neutral",
                        overallCredibility: 0,
                        overallCredibilityEmoji: "ğŸ”´",
                        speakerCount: 0,
                        duration: "0:00",
                    },
                    metadata: {
                        fileName,
                        fileType: this.getFileType(mimeType),
                        mimeType,
                        fileSize,
                        language: "pl",
                    },
                    formattedTranscript: "",
                    error: "Nie udaÅ‚o siÄ™ rozpoznaÄ‡ mowy w pliku. Upewnij siÄ™, Å¼e plik zawiera wyraÅºnÄ… mowÄ™.",
                };
            }
            // Step 2: Analyze with GPT-4
            const analysis = await this.analyzeTranscript(rawTranscript);
            // Step 3: Format output
            const formattedTranscript = this.formatTranscript(analysis.segments, analysis.summary);
            return {
                success: true,
                rawTranscript,
                segments: analysis.segments,
                summary: analysis.summary,
                metadata: {
                    fileName,
                    fileType: this.getFileType(mimeType),
                    mimeType,
                    fileSize,
                    language: "pl",
                },
                formattedTranscript,
            };
        }
        catch (error) {
            console.error("[AudioTranscriber] Error:", error);
            return {
                success: false,
                rawTranscript: "",
                segments: [],
                summary: {
                    averageTension: 0,
                    dominantSentiment: "neutral",
                    overallCredibility: 0,
                    overallCredibilityEmoji: "ğŸ”´",
                    speakerCount: 0,
                    duration: "0:00",
                },
                metadata: {
                    fileName,
                    fileType: this.getFileType(mimeType),
                    mimeType,
                    fileSize,
                    language: "pl",
                },
                formattedTranscript: "",
                error: error instanceof Error ? error.message : "BÅ‚Ä…d transkrypcji",
            };
        }
    }
    async whisperTranscribe(fileBuffer, fileName) {
        if (!this.sttClient)
            throw new Error("STT client not initialized");
        // Convert buffer to File-like object for OpenAI
        const file = await toFile(Readable.from(fileBuffer), fileName);
        const response = await this.sttClient.audio.transcriptions.create({
            file,
            model: this.sttModel,
            language: "pl",
            response_format: "text",
        });
        return response;
    }
    async analyzeTranscript(transcript) {
        if (!this.llmClient)
            throw new Error("LLM client not initialized");
        const systemPrompt = `JesteÅ› ekspertem analizy lingwistycznej i psychologicznej. Przeanalizuj transkrypcjÄ™ i zwrÃ³Ä‡ szczegÃ³Å‚owÄ… analizÄ™ w formacie JSON.

WAÅ»NE: Tekst wypowiedzi (pole "text") ZAWSZE musi byÄ‡ w jÄ™zyku polskim. JeÅ›li oryginalna transkrypcja jest w innym jÄ™zyku, przetÅ‚umacz jÄ… na polski.

Dla KAÅ»DEJ wypowiedzi okreÅ›l:
1. **speaker** - identyfikuj rozmÃ³wcÃ³w jako "RozmÃ³wca 1", "RozmÃ³wca 2" itd. na podstawie kontekstu, zmiany tonu, odpowiedzi na pytania
2. **sentiment** - "positive", "neutral", lub "negative"
3. **emotion** - gÅ‚Ã³wna emocja (np. "spokÃ³j", "zaniepokojenie", "frustracja", "entuzjazm", "wahanie", "pewnoÅ›Ä‡ siebie", "defensywnoÅ›Ä‡")
4. **emotionEmoji** - emoji odpowiadajÄ…ce emocji (ğŸ˜ŠğŸ˜¢ğŸ˜ ğŸ˜¨ğŸ¤”ğŸ˜°ğŸ˜¤ğŸ™‚ğŸ˜)
5. **tension** - napiÄ™cie emocjonalne 1-10 (1=spokÃ³j, 10=silne napiÄ™cie)
6. **credibility** - wiarygodnoÅ›Ä‡ 0-100% na podstawie:
   - SpÃ³jnoÅ›Ä‡ wypowiedzi
   - Wahania, zmiany zdania ("wÅ‚aÅ›ciwie", "albo", "nie pamiÄ™tam")
   - Nadmierne szczegÃ³Å‚y lub ich brak
   - Unikanie odpowiedzi
   - DefensywnoÅ›Ä‡
   - Kontradykcje
7. **credibilityEmoji** - emoji: 90-100%=âœ…, 70-89%=ğŸŸ¢, 50-69%=ğŸŸ¡, 30-49%=âš ï¸, 0-29%=ğŸ”´

Odpowiedz TYLKO w formacie JSON:
{
  "segments": [
    {
      "timestamp": "00:00:00",
      "speaker": "RozmÃ³wca 1",
      "text": "tekst wypowiedzi",
      "sentiment": "neutral",
      "emotion": "spokÃ³j",
      "emotionEmoji": "ğŸ™‚",
      "tension": 2,
      "credibility": 95,
      "credibilityEmoji": "âœ…"
    }
  ],
  "summary": {
    "averageTension": 3.5,
    "dominantSentiment": "neutral",
    "overallCredibility": 85,
    "overallCredibilityEmoji": "ğŸŸ¢",
    "speakerCount": 2,
    "duration": "5:32"
  }
}`;
        const response = await this.llmClient.chat.completions.create({
            model: this.llmModel,
            messages: [
                { role: "system", content: systemPrompt },
                {
                    role: "user",
                    content: `Przeanalizuj tÄ™ transkrypcjÄ™:\n\n${transcript}`,
                },
            ],
            temperature: 0.3,
            response_format: { type: "json_object" },
        });
        const content = response.choices[0]?.message?.content;
        if (!content) {
            throw new Error("Brak odpowiedzi od GPT-4");
        }
        try {
            const parsed = JSON.parse(content);
            return {
                segments: parsed.segments || [],
                summary: parsed.summary || {
                    averageTension: 0,
                    dominantSentiment: "neutral",
                    overallCredibility: 0,
                    overallCredibilityEmoji: "ğŸ”´",
                    speakerCount: 0,
                    duration: "0:00",
                },
            };
        }
        catch {
            console.error("[AudioTranscriber] Failed to parse GPT response:", content);
            // Return basic analysis if parsing fails
            return {
                segments: [
                    {
                        timestamp: "00:00:00",
                        speaker: "RozmÃ³wca",
                        text: transcript,
                        sentiment: "neutral",
                        emotion: "neutralny",
                        emotionEmoji: "ğŸ˜",
                        tension: 5,
                        credibility: 50,
                        credibilityEmoji: "ğŸŸ¡",
                    },
                ],
                summary: {
                    averageTension: 5,
                    dominantSentiment: "neutral",
                    overallCredibility: 50,
                    overallCredibilityEmoji: "ğŸŸ¡",
                    speakerCount: 1,
                    duration: "0:00",
                },
            };
        }
    }
    formatTranscript(segments, summary) {
        let output = `ğŸ“ TRANSKRYPCJA AUDIO/VIDEO\n`;
        output += `â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n`;
        for (const seg of segments) {
            output += `[${seg.timestamp}] ğŸ‘¤ ${seg.speaker}:\n`;
            output += `"${seg.text}"\n`;
            output += `ğŸ“Š Sentyment: ${this.translateSentiment(seg.sentiment)} | Emocja: ${seg.emotionEmoji} ${seg.emotion}\n`;
            output += `âš¡ NapiÄ™cie: ${seg.tension}/10 | ğŸ¯ WiarygodnoÅ›Ä‡: ${seg.credibility}% ${seg.credibilityEmoji}\n\n`;
        }
        output += `â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n`;
        output += `ğŸ“ˆ PODSUMOWANIE ANALIZY:\n`;
        output += `â€¢ Czas trwania: ${summary.duration}\n`;
        output += `â€¢ Liczba rozmÃ³wcÃ³w: ${summary.speakerCount}\n`;
        output += `â€¢ Åšrednie napiÄ™cie: ${summary.averageTension.toFixed(1)}/10\n`;
        output += `â€¢ DominujÄ…cy sentyment: ${this.translateSentiment(summary.dominantSentiment)}\n`;
        output += `â€¢ OgÃ³lna wiarygodnoÅ›Ä‡: ${summary.overallCredibility}% ${summary.overallCredibilityEmoji}\n`;
        return output;
    }
    translateSentiment(sentiment) {
        switch (sentiment) {
            case "positive":
                return "Pozytywny";
            case "negative":
                return "Negatywny";
            case "neutral":
                return "Neutralny";
            default:
                return sentiment;
        }
    }
    getFileType(mimeType) {
        if (AUDIO_MIME_TYPES.includes(mimeType))
            return "audio";
        if (VIDEO_MIME_TYPES.includes(mimeType))
            return "video";
        return "unknown";
    }
    getCredibilityEmoji(credibility) {
        if (credibility >= 90)
            return "âœ…";
        if (credibility >= 70)
            return "ğŸŸ¢";
        if (credibility >= 50)
            return "ğŸŸ¡";
        if (credibility >= 30)
            return "âš ï¸";
        return "ğŸ”´";
    }
}
//# sourceMappingURL=audio-transcriber.js.map