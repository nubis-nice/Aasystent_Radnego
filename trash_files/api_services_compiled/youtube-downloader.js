import { spawn } from "node:child_process";
import { existsSync, mkdirSync, unlinkSync, readFileSync } from "node:fs";
import { join } from "node:path";
import { tmpdir } from "node:os";
import { randomUUID } from "node:crypto";
import { setTimeout } from "node:timers";
import { getSTTClient, getLLMClient, getAIConfig } from "../ai/index.js";
import { getAudioPreprocessor } from "./audio-preprocessor.js";
export class YouTubeDownloader {
    sttClient = null;
    llmClient = null;
    tempDir;
    userId = null;
    sttModel = "whisper-1";
    llmModel = "gpt-4o";
    constructor() {
        this.tempDir = join(tmpdir(), "aasystent-youtube");
        if (!existsSync(this.tempDir)) {
            mkdirSync(this.tempDir, { recursive: true });
        }
    }
    /**
     * Normalizuj nazwƒô modelu STT dla faster-whisper-server
     * Mapuje r√≥≈ºne formaty nazw na prawid≈Çowe nazwy modeli
     */
    normalizeSTTModel(modelName, provider) {
        // Dla OpenAI API u≈ºywamy whisper-1
        if (provider === "openai") {
            return "whisper-1";
        }
        // Dla faster-whisper-server normalizujemy nazwy
        const normalizedModel = modelName.toLowerCase().trim();
        // Usu≈Ñ suffix :latest je≈õli istnieje (np. dimavz/whisper-tiny:latest)
        const withoutTag = normalizedModel.replace(/:latest$/, "");
        // Mapowanie nieprawid≈Çowych nazw na prawid≈Çowe
        const modelMapping = {
            whisper: "large-v3",
            "whisper-1": "large-v3",
            "whisper-tiny": "tiny",
            "whisper-base": "base",
            "whisper-small": "small",
            "whisper-medium": "medium",
            "whisper-large": "large-v3",
            "whisper-large-v2": "large-v2",
            "whisper-large-v3": "large-v3",
            "dimavz/whisper-tiny": "tiny",
            "dimavz/whisper-base": "base",
            "dimavz/whisper-small": "small",
            "dimavz/whisper-medium": "medium",
            "dimavz/whisper-large": "large-v3",
        };
        // Sprawd≈∫ czy mamy mapowanie
        if (modelMapping[withoutTag]) {
            console.log(`[YouTubeDownloader] Normalized STT model: ${modelName} -> ${modelMapping[withoutTag]}`);
            return modelMapping[withoutTag];
        }
        // Sprawd≈∫ czy to ju≈º prawid≈Çowy format Systran/faster-whisper-*
        if (withoutTag.startsWith("systran/faster-whisper-")) {
            return modelName; // Ju≈º prawid≈Çowy format
        }
        // Sprawd≈∫ czy to prawid≈Çowy rozmiar modelu
        const validSizes = [
            "tiny",
            "tiny.en",
            "base",
            "base.en",
            "small",
            "small.en",
            "medium",
            "medium.en",
            "large",
            "large-v1",
            "large-v2",
            "large-v3",
            "distil-large-v2",
            "distil-medium.en",
            "distil-small.en",
            "distil-large-v3",
        ];
        if (validSizes.includes(withoutTag)) {
            return withoutTag;
        }
        // Domy≈õlnie u≈ºyj large-v3 dla najlepszej jako≈õci
        console.warn(`[YouTubeDownloader] Unknown STT model "${modelName}", using large-v3`);
        return "large-v3";
    }
    /**
     * Inicjalizacja z konfiguracjƒÖ u≈ºytkownika przez AIClientFactory
     */
    async initializeWithUserConfig(userId) {
        this.userId = userId;
        // Pobierz klienta STT (Speech-to-Text) z fabryki
        this.sttClient = await getSTTClient(userId);
        // Pobierz konfiguracjƒô STT aby znaƒá model
        const sttConfig = await getAIConfig(userId, "stt");
        this.sttModel = this.normalizeSTTModel(sttConfig.modelName, sttConfig.provider);
        // Pobierz klienta LLM do analizy transkryptu
        this.llmClient = await getLLMClient(userId);
        // Pobierz konfiguracjƒô LLM aby znaƒá model
        const llmConfig = await getAIConfig(userId, "llm");
        this.llmModel = llmConfig.modelName;
        console.log(`[YouTubeDownloader] Initialized for user ${userId.substring(0, 8)}...`);
        console.log(`[YouTubeDownloader] STT: provider=${sttConfig.provider}, model=${this.sttModel}, baseUrl=${sttConfig.baseUrl}`);
        console.log(`[YouTubeDownloader] LLM: model=${this.llmModel}`);
    }
    async downloadAudio(videoUrl, enableChunking = true) {
        try {
            const videoId = this.extractVideoId(videoUrl);
            if (!videoId) {
                return { success: false, error: "Nieprawid≈Çowy URL YouTube" };
            }
            const baseId = randomUUID();
            const rawPath = join(this.tempDir, `audio-${baseId}-raw`); // yt-dlp doda rozszerzenie
            const whisperPath = join(this.tempDir, `audio-${baseId}.wav`);
            console.log(`[YouTubeDownloader] Downloading bestaudio: ${videoUrl}`);
            const result = await this.runYtDlp(videoUrl, rawPath);
            if (!result.success || !result.audioPath) {
                return result;
            }
            // BEST PRACTICE: Konwertuj do formatu optymalnego dla Whisper
            // 16kHz mono 16-bit PCM WAV z normalizacjƒÖ g≈Ço≈õno≈õci
            console.log(`[YouTubeDownloader] Converting to Whisper format...`);
            const preprocessor = getAudioPreprocessor();
            await preprocessor.convertToWhisperFormat(result.audioPath, whisperPath);
            // Usu≈Ñ surowy plik
            try {
                unlinkSync(result.audioPath);
            }
            catch {
                /* ignore */
            }
            // Dziel na segmenty je≈õli potrzeba
            if (enableChunking) {
                console.log(`[YouTubeDownloader] Checking if splitting needed...`);
                const splitResult = await preprocessor.splitAudioByTime(whisperPath, 600);
                if (splitResult.success && splitResult.parts.length > 0) {
                    console.log(`[YouTubeDownloader] Split into ${splitResult.parts.length} parts`);
                    return {
                        success: true,
                        audioPath: whisperPath,
                        title: result.title,
                        duration: result.duration,
                        parts: splitResult.parts,
                        splitMetadata: {
                            totalDuration: splitResult.totalDuration,
                            chunkingEnabled: true,
                        },
                    };
                }
                else {
                    console.log(`[YouTubeDownloader] No splitting needed (audio < 10 min)`);
                }
            }
            return {
                success: true,
                audioPath: whisperPath,
                title: result.title,
                duration: result.duration,
            };
        }
        catch (error) {
            console.error("[YouTubeDownloader] Download error:", error);
            return {
                success: false,
                error: error instanceof Error ? error.message : "B≈ÇƒÖd pobierania audio",
            };
        }
    }
    extractVideoId(url) {
        const match = url.match(/(?:v=|\/)([\w-]{11})(?:\?|&|$)/);
        return match ? match[1] : null;
    }
    runYtDlp(videoUrl, outputPath) {
        return new Promise((resolve) => {
            // Remove extension - yt-dlp will add extension
            const outputBase = outputPath.replace(/\.(mp3|wav|webm|m4a)$/, "");
            // BEST PRACTICE dla Whisper Large v3:
            // 1. Pobierz audio (preferuj m4a/webm, fallback do dowolnego)
            // 2. Konwertuj do 16kHz mono 16-bit PCM WAV w osobnym kroku
            const args = [
                "-x", // Extract audio
                "-f",
                "bestaudio[ext=m4a]/bestaudio[ext=webm]/bestaudio/best", // Fallback chain
                "--audio-format",
                "m4a", // Konwertuj do m4a je≈õli inny format
                "-o",
                `${outputBase}.%(ext)s`,
                "--no-playlist",
                "--print",
                "after_move:filepath",
                "--print",
                "%(title)s|||%(duration_string)s",
                // U≈ºyj tylko web client (unikaj ios kt√≥ry wymaga PO Token)
                "--extractor-args",
                "youtube:player_client=web",
                videoUrl,
            ];
            // Add FFmpeg location if specified in environment
            const ffmpegPath = process.env.FFMPEG_PATH;
            if (ffmpegPath) {
                args.unshift("--ffmpeg-location", ffmpegPath);
            }
            // Use full path to yt-dlp
            const ytdlpPath = process.env.YTDLP_PATH ||
                "C:\\ProgramData\\chocolatey\\lib\\yt-dlp\\tools\\x64\\yt-dlp.exe";
            console.log(`[YouTubeDownloader] Using yt-dlp path: ${ytdlpPath}`);
            console.log(`[YouTubeDownloader] Running command with args: ${args
                .slice(0, 5)
                .join(" ")}...`);
            const childProcess = spawn(ytdlpPath, args);
            let stdout = "";
            let stderr = "";
            childProcess.stdout.on("data", (data) => {
                stdout += data.toString();
            });
            childProcess.stderr.on("data", (data) => {
                stderr += data.toString();
            });
            childProcess.on("close", (code) => {
                if (code === 0) {
                    // Parse output - yt-dlp prints in order: filepath, then title|||duration
                    // But we need to identify which line is which
                    const lines = stdout
                        .trim()
                        .split("\n")
                        .filter((l) => l.trim());
                    let actualFilePath = "";
                    let title = "Nieznany tytu≈Ç";
                    let duration = "0:00";
                    for (const line of lines) {
                        if (line.includes("|||")) {
                            // This is the metadata line: title|||duration
                            const parts = line.split("|||");
                            title = parts[0] || title;
                            duration = parts[1] || duration;
                        }
                        else if (line.endsWith(".m4a") ||
                            line.endsWith(".webm") ||
                            line.endsWith(".mp3") ||
                            line.endsWith(".wav") ||
                            line.endsWith(".opus")) {
                            // This is the filepath
                            actualFilePath = line;
                        }
                    }
                    // Fallback to expected output path if no filepath found
                    if (!actualFilePath) {
                        actualFilePath = `${outputBase}.m4a`;
                    }
                    console.log(`[YouTubeDownloader] Output file: ${actualFilePath}`);
                    resolve({
                        success: true,
                        audioPath: actualFilePath,
                        title: title || "Nieznany tytu≈Ç",
                        duration: duration || "0:00",
                    });
                }
                else {
                    console.error("[YouTubeDownloader] yt-dlp stderr:", stderr);
                    // Check for common errors
                    if (stderr.includes("not found") ||
                        stderr.includes("nie odnaleziono")) {
                        resolve({
                            success: false,
                            error: "yt-dlp nie jest zainstalowany. Zainstaluj go poleceniem: pip install yt-dlp",
                        });
                    }
                    else if (stderr.includes("File is larger than max-filesize")) {
                        resolve({
                            success: false,
                            error: "Plik audio jest zbyt du≈ºy (max 25MB). Wybierz kr√≥tsze wideo.",
                        });
                    }
                    else {
                        resolve({
                            success: false,
                            error: `B≈ÇƒÖd pobierania: ${stderr.slice(0, 200)}`,
                        });
                    }
                }
            });
            childProcess.on("error", (err) => {
                if (err.code === "ENOENT") {
                    resolve({
                        success: false,
                        error: "yt-dlp nie jest zainstalowany. Zainstaluj go poleceniem: pip install yt-dlp",
                    });
                }
                else {
                    resolve({
                        success: false,
                        error: `B≈ÇƒÖd uruchomienia yt-dlp: ${err.message}`,
                    });
                }
            });
        });
    }
    /**
     * Transkrybuj pojedynczy plik audio (dla kr√≥tkich nagra≈Ñ)
     */
    async transcribeSingleFile(audioPath) {
        if (!this.sttClient) {
            throw new Error("STT client not initialized");
        }
        const { createReadStream } = await import("node:fs");
        const audioStream = createReadStream(audioPath);
        console.log(`[YouTubeDownloader] Using STT model: ${this.sttModel}`);
        console.log(`[YouTubeDownloader] Starting STT transcription (timeout: 10 minutes)...`);
        // Prompt kontekstowy dla Whisper - bez konkretnych s≈Ç√≥w kt√≥re mogƒÖ byƒá powtarzane
        const contextPrompt = "Transkrypcja oficjalnego posiedzenia samorzƒÖdowego w jƒôzyku polskim. " +
            "Nagranie zawiera formalne wypowiedzi, g≈Çosowania i dyskusje.";
        // Timeout 10 minut
        const sttTimeoutMs = 10 * 60 * 1000;
        const sttStartTime = Date.now();
        const transcriptionPromise = this.sttClient.audio.transcriptions.create({
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            file: audioStream,
            model: this.sttModel,
            language: "pl",
            response_format: "text",
            prompt: contextPrompt,
        });
        const timeoutPromise = new Promise((_, reject) => setTimeout(() => reject(new Error(`STT API timeout po ${sttTimeoutMs / 1000}s`)), sttTimeoutMs));
        try {
            const transcription = await Promise.race([
                transcriptionPromise,
                timeoutPromise,
            ]);
            const sttDuration = ((Date.now() - sttStartTime) / 1000).toFixed(1);
            console.log(`[YouTubeDownloader] STT completed in ${sttDuration}s`);
            return transcription;
        }
        catch (error) {
            const sttDuration = ((Date.now() - sttStartTime) / 1000).toFixed(1);
            console.error(`[YouTubeDownloader] STT failed after ${sttDuration}s:`, error);
            throw new Error(`B≈ÇƒÖd transkrypcji STT: ${error instanceof Error ? error.message : "Unknown error"}`);
        }
    }
    /**
     * Transkrybuj pojedynczy chunk audio z timeout
     */
    async transcribeChunk(chunkPath, chunkIndex, totalChunks) {
        if (!this.sttClient) {
            throw new Error("STT client not initialized");
        }
        const { createReadStream } = await import("node:fs");
        const audioStream = createReadStream(chunkPath);
        console.log(`[YouTubeDownloader] Transcribing chunk ${chunkIndex}/${totalChunks}: ${chunkPath}`);
        // Prompt kontekstowy dla Whisper - bez konkretnych s≈Ç√≥w kt√≥re mogƒÖ byƒá powtarzane
        // Informuje model o kontek≈õcie bez powodowania halucynacji
        const contextPrompt = "Transkrypcja oficjalnego posiedzenia samorzƒÖdowego w jƒôzyku polskim. " +
            "Nagranie zawiera formalne wypowiedzi, g≈Çosowania i dyskusje.";
        // Timeout 5 minut per chunk (ka≈ºdy chunk to max 10 min audio)
        const chunkTimeoutMs = 5 * 60 * 1000;
        const startTime = Date.now();
        const transcriptionPromise = this.sttClient.audio.transcriptions.create({
            // eslint-disable-next-line @typescript-eslint/no-explicit-any
            file: audioStream,
            model: this.sttModel,
            language: "pl",
            response_format: "text",
            prompt: contextPrompt,
        });
        const timeoutPromise = new Promise((_, reject) => setTimeout(() => reject(new Error(`Chunk ${chunkIndex} timeout po ${chunkTimeoutMs / 1000}s`)), chunkTimeoutMs));
        const result = await Promise.race([transcriptionPromise, timeoutPromise]);
        const duration = ((Date.now() - startTime) / 1000).toFixed(1);
        console.log(`[YouTubeDownloader] Chunk ${chunkIndex}/${totalChunks} completed in ${duration}s`);
        return result;
    }
    async transcribeAndAnalyze(audioPath, videoId, videoTitle, videoUrl, precomputedParts) {
        if (!this.sttClient) {
            throw new Error("STT client not initialized. Call initializeWithUserConfig first.");
        }
        let processedPath = audioPath;
        let audioAnalysis;
        try {
            console.log(`[YouTubeDownloader] Transcribing: ${audioPath}`);
            // UWAGA: Stary preprocessAdaptive() wy≈ÇƒÖczony - preprocessing jest teraz per-segment
            // w chunked transcription (prepareSegmentForWhisper) dla lepszej jako≈õci
            // i unikniƒôcia podw√≥jnego dzielenia pliku
            // Read audio file
            const audioBuffer = readFileSync(processedPath);
            const fileSizeMB = (audioBuffer.length / 1024 / 1024).toFixed(2);
            console.log(`[YouTubeDownloader] Audio file size: ${fileSizeMB}MB`);
            // Sprawd≈∫ czy audio jest d≈Çugie (> 25MB) lub mamy precomputed parts
            const useChunkedTranscription = audioBuffer.length > 25 * 1024 * 1024 ||
                (precomputedParts && precomputedParts.length > 0);
            let rawTranscript;
            if (useChunkedTranscription) {
                console.log(`[YouTubeDownloader] Large audio detected, using chunked transcription...`);
                const preprocessor = getAudioPreprocessor();
                // U≈ºyj precomputed parts je≈õli dostƒôpne, w przeciwnym razie podziel
                let parts;
                if (precomputedParts && precomputedParts.length > 0) {
                    console.log(`[YouTubeDownloader] Using ${precomputedParts.length} precomputed parts (no re-split)`);
                    parts = precomputedParts;
                }
                else {
                    // Fallback: podziel audio na 10-minutowe czƒô≈õci
                    const splitResult = await preprocessor.splitAudioByTime(processedPath, 600);
                    if (splitResult.success && splitResult.parts.length > 0) {
                        parts = splitResult.parts;
                        console.log(`[YouTubeDownloader] Split into ${parts.length} chunks`);
                    }
                    else {
                        parts = [];
                    }
                }
                if (parts.length > 0) {
                    console.log(`[YouTubeDownloader] Transcribing ${parts.length} chunks...`);
                    const transcripts = [];
                    for (let i = 0; i < parts.length; i++) {
                        const part = parts[i];
                        try {
                            // Audio jest ju≈º w formacie Whisper (16kHz mono) - transkrybuj bezpo≈õrednio
                            const chunkTranscript = await this.transcribeChunk(part.filePath, i + 1, parts.length);
                            transcripts.push(chunkTranscript);
                        }
                        catch (chunkError) {
                            console.error(`[YouTubeDownloader] Chunk ${i + 1} failed:`, chunkError);
                            transcripts.push(`[Chunk ${i + 1} failed: ${chunkError instanceof Error
                                ? chunkError.message
                                : "Unknown error"}]`);
                        }
                    }
                    // Po≈ÇƒÖcz transkrypcje wszystkich chunk√≥w
                    rawTranscript = transcripts.join("\n\n");
                    console.log(`[YouTubeDownloader] All chunks transcribed, total length: ${rawTranscript.length} chars`);
                }
                else {
                    // Fallback - audio jest ju≈º w formacie Whisper
                    console.log(`[YouTubeDownloader] Split failed or not needed, using single transcription`);
                    rawTranscript = await this.transcribeSingleFile(processedPath);
                }
            }
            else {
                // Audio jest ju≈º w formacie Whisper (16kHz mono) - transkrybuj bezpo≈õrednio
                console.log(`[YouTubeDownloader] Short audio, direct transcription...`);
                rawTranscript = await this.transcribeSingleFile(processedPath);
            }
            console.log(`[YouTubeDownloader] Transcript length: ${rawTranscript.length} chars`);
            if (!rawTranscript || rawTranscript.trim().length === 0) {
                return {
                    success: false,
                    rawTranscript: "",
                    formattedTranscript: "",
                    segments: [],
                    summary: {
                        averageTension: 0,
                        dominantSentiment: "neutral",
                        overallCredibility: 0,
                        overallCredibilityEmoji: "üî¥",
                        speakerCount: 0,
                        duration: "0:00",
                    },
                    metadata: { videoId, videoTitle, videoUrl },
                    error: "Nie uda≈Ço siƒô rozpoznaƒá mowy w nagraniu",
                };
            }
            // Correct transcription errors
            const correctedTranscript = await this.correctTranscript(rawTranscript);
            console.log("[YouTubeDownloader] Transcript corrected");
            // Analyze with GPT-4
            const analysis = await this.analyzeTranscript(correctedTranscript);
            // Format output as Markdown for export
            const formattedTranscript = this.formatTranscriptMarkdown(correctedTranscript, analysis.segments, analysis.summary, videoTitle, videoUrl);
            // Cleanup temp files
            try {
                unlinkSync(audioPath);
                if (processedPath !== audioPath && existsSync(processedPath)) {
                    unlinkSync(processedPath);
                }
            }
            catch {
                /* ignore cleanup errors */
            }
            return {
                success: true,
                rawTranscript,
                formattedTranscript,
                segments: analysis.segments,
                summary: analysis.summary,
                metadata: { videoId, videoTitle, videoUrl },
                audioAnalysis,
            };
        }
        catch (error) {
            console.error("[YouTubeDownloader] Transcription error:", error);
            // Cleanup temp files
            try {
                unlinkSync(audioPath);
                if (processedPath !== audioPath && existsSync(processedPath)) {
                    unlinkSync(processedPath);
                }
            }
            catch {
                /* ignore cleanup errors */
            }
            return {
                success: false,
                rawTranscript: "",
                formattedTranscript: "",
                segments: [],
                summary: {
                    averageTension: 0,
                    dominantSentiment: "neutral",
                    overallCredibility: 0,
                    overallCredibilityEmoji: "üî¥",
                    speakerCount: 0,
                    duration: "0:00",
                },
                metadata: { videoId, videoTitle, videoUrl },
                error: error instanceof Error ? error.message : "B≈ÇƒÖd transkrypcji",
            };
        }
    }
    /**
     * Usuwa powtarzajƒÖce siƒô frazy z transkrypcji (halucynacje Whisper)
     * V3: Algorytm iteracyjny dla fraz wielowyrazowych
     */
    removeRepetitions(text) {
        const originalLength = text.length;
        let cleaned = text;
        console.log(`[YouTubeDownloader] removeRepetitions() input: ${originalLength} chars`);
        // 1. Podziel na elementy (s≈Çowa/frazy oddzielone przecinkami)
        const elements = cleaned.split(/,\s*/);
        if (elements.length > 10) {
            // Deduplikacja element√≥w oddzielonych przecinkami
            const seen = new Map();
            const dedupedElements = [];
            for (const el of elements) {
                const norm = el.trim().toLowerCase();
                if (norm.length < 2)
                    continue;
                const count = seen.get(norm) || 0;
                if (count < 2) {
                    // Pozw√≥l max 2 wystƒÖpienia
                    dedupedElements.push(el.trim());
                    seen.set(norm, count + 1);
                }
            }
            // Je≈õli usunƒôli≈õmy du≈ºo, u≈ºyj nowej wersji
            if (dedupedElements.length < elements.length * 0.5) {
                cleaned = dedupedElements.join(", ");
                console.log(`[YouTubeDownloader] Comma dedup: ${elements.length} -> ${dedupedElements.length} elements`);
            }
        }
        // 2. Podziel na s≈Çowa i szukaj powtarzajƒÖcych siƒô sekwencji
        const words = cleaned.split(/\s+/);
        if (words.length > 20) {
            const dedupedWords = [];
            let i = 0;
            while (i < words.length) {
                // Szukaj powtarzajƒÖcych siƒô sekwencji 1-4 s≈Ç√≥w
                let foundRepeat = false;
                for (let seqLen = 4; seqLen >= 1; seqLen--) {
                    if (i + seqLen * 3 > words.length)
                        continue;
                    const seq = words
                        .slice(i, i + seqLen)
                        .join(" ")
                        .toLowerCase();
                    let repeatCount = 1;
                    let j = i + seqLen;
                    while (j + seqLen <= words.length) {
                        const nextSeq = words
                            .slice(j, j + seqLen)
                            .join(" ")
                            .toLowerCase();
                        // Por√≥wnaj z tolerancjƒÖ na drobne r√≥≈ºnice (liter√≥wki)
                        if (seq === nextSeq || this.stringSimilarity(seq, nextSeq) > 0.85) {
                            repeatCount++;
                            j += seqLen;
                        }
                        else {
                            break;
                        }
                    }
                    if (repeatCount >= 3) {
                        // Znaleziono 3+ powt√≥rze≈Ñ
                        dedupedWords.push(...words.slice(i, i + seqLen));
                        i = j; // Przeskocz wszystkie powt√≥rzenia
                        foundRepeat = true;
                        break;
                    }
                }
                if (!foundRepeat) {
                    dedupedWords.push(words[i]);
                    i++;
                }
            }
            if (dedupedWords.length < words.length * 0.8) {
                cleaned = dedupedWords.join(" ");
                console.log(`[YouTubeDownloader] Word seq dedup: ${words.length} -> ${dedupedWords.length} words`);
            }
        }
        // 3. Podziel na zdania i deduplikuj
        const sentences = cleaned.split(/(?<=[.!?])\s+/);
        const seenSentences = new Set();
        const dedupedSentences = [];
        for (const sentence of sentences) {
            const trimmed = sentence.trim();
            if (trimmed.length < 3)
                continue;
            const normalized = trimmed
                .toLowerCase()
                .replace(/[^a-zƒÖƒáƒô≈Ç≈Ñ√≥≈õ≈∫≈º\s]/g, "")
                .trim();
            // Sprawd≈∫ czy podobne zdanie ju≈º by≈Ço
            let isDuplicate = false;
            for (const seen of seenSentences) {
                if (normalized === seen ||
                    this.stringSimilarity(normalized, seen) > 0.8) {
                    isDuplicate = true;
                    break;
                }
            }
            if (!isDuplicate) {
                dedupedSentences.push(trimmed);
                seenSentences.add(normalized);
            }
        }
        cleaned = dedupedSentences.join(" ");
        // 4. Finalne czyszczenie
        cleaned = cleaned
            .replace(/,\s*,+/g, ",")
            .replace(/\s{2,}/g, " ")
            .replace(/,\s*\./g, ".")
            .trim();
        const removedChars = originalLength - cleaned.length;
        const removedPercent = (removedChars / originalLength) * 100;
        console.log(`[YouTubeDownloader] removeRepetitions() removed ${removedChars} chars (${removedPercent.toFixed(1)}%)`);
        // 5. Wykryj halucynacje Whisper
        // a) Je≈õli tekst jest g≈Ç√≥wnie powt√≥rzeniami (>85% usuniƒôte)
        if (removedPercent > 85 && cleaned.length < 200) {
            console.log(`[YouTubeDownloader] Text is mostly repetitions (${removedPercent.toFixed(1)}%), audio has too much noise`);
            return "[Za du≈ºe szumy w nagraniu - nie uda≈Ço siƒô rozpoznaƒá mowy]";
        }
        // b) Je≈õli pozosta≈Ça bardzo kr√≥tka unikalna tre≈õƒá w stosunku do orygina≈Çu
        // (np. "Dzie≈Ñ dobry" z 10000 znak√≥w orygina≈Çu = halucynacja)
        const uniqueWordsCount = new Set(cleaned.toLowerCase().split(/\s+/)).size;
        const originalWordsCount = text.split(/\s+/).length;
        if (uniqueWordsCount < 10 &&
            originalWordsCount > 50 &&
            cleaned.length < originalLength * 0.1) {
            console.log(`[YouTubeDownloader] Detected hallucination: only ${uniqueWordsCount} unique words from ${originalWordsCount} original words`);
            return "[Za du≈ºe szumy w nagraniu - nie uda≈Ço siƒô rozpoznaƒá mowy]";
        }
        // c) Sprawd≈∫ czy dominuje jedna fraza (>50% tekstu to ta sama fraza)
        const phraseCount = new Map();
        const phrases = cleaned.split(/[.!?]+/).map((p) => p.trim().toLowerCase());
        for (const phrase of phrases) {
            if (phrase.length > 3) {
                phraseCount.set(phrase, (phraseCount.get(phrase) || 0) + 1);
            }
        }
        const maxPhraseCount = Math.max(...phraseCount.values(), 0);
        if (maxPhraseCount > phrases.length * 0.5 && phrases.length > 5) {
            console.log(`[YouTubeDownloader] Detected repetitive hallucination: one phrase appears ${maxPhraseCount}/${phrases.length} times`);
            return "[Za du≈ºe szumy w nagraniu - nie uda≈Ço siƒô rozpoznaƒá mowy]";
        }
        return cleaned;
    }
    /**
     * Oblicza podobie≈Ñstwo dw√≥ch string√≥w (0-1)
     */
    stringSimilarity(str1, str2) {
        if (str1 === str2)
            return 1;
        if (str1.length === 0 || str2.length === 0)
            return 0;
        // Prosty algorytm oparty na wsp√≥lnych s≈Çowach
        const words1 = new Set(str1.split(/\s+/));
        const words2 = new Set(str2.split(/\s+/));
        let common = 0;
        for (const word of words1) {
            if (words2.has(word))
                common++;
        }
        return (2 * common) / (words1.size + words2.size);
    }
    async correctTranscript(rawTranscript) {
        if (!this.llmClient)
            throw new Error("LLM client not initialized");
        // Najpierw usu≈Ñ powt√≥rzenia (halucynacje Whisper)
        const deduped = this.removeRepetitions(rawTranscript);
        console.log(`[YouTubeDownloader] After dedup: ${deduped.length} chars (was ${rawTranscript.length})`);
        console.log("[YouTubeDownloader] Correcting transcript errors...");
        const correctionPrompt = `Jeste≈õ korektorem transkrypcji sesji rady miejskiej/gminnej. 

ZADANIE: Popraw b≈Çƒôdy w transkrypcji, zachowujƒÖc oryginalny kontekst i sens wypowiedzi.

ZASADY:
1. Poprawiaj TYLKO oczywiste b≈Çƒôdy transkrypcji (przekrƒôcone s≈Çowa, liter√≥wki)
2. Poprawiaj b≈Çƒôdy stylistyczne (interpunkcja, wielkie litery na poczƒÖtku zda≈Ñ)
3. NIE zmieniaj sensu wypowiedzi
4. NIE dodawaj w≈Çasnych tre≈õci
5. Zachowaj strukturƒô i podzia≈Ç na akapity
6. Poprawiaj typowe b≈Çƒôdy ASR: "rady" zamiast "raty", "sesja" zamiast "sesjƒô" itp.
7. USU≈É powtarzajƒÖce siƒô frazy (halucynacje ASR) - je≈õli to samo zdanie/fraza powtarza siƒô wielokrotnie, zostaw tylko jedno wystƒÖpienie
8. Je≈õli tekst jest bardzo kr√≥tki lub sk≈Çada siƒô g≈Ç√≥wnie z powt√≥rze≈Ñ, napisz "[Brak rozpoznawalnej mowy w nagraniu]"

Zwr√≥ƒá TYLKO poprawiony tekst, bez komentarzy.`;
        const response = await this.llmClient.chat.completions.create({
            model: this.llmModel,
            messages: [
                { role: "system", content: correctionPrompt },
                { role: "user", content: deduped.slice(0, 30000) },
            ],
            temperature: 0.1,
        });
        return response.choices[0]?.message?.content || rawTranscript;
    }
    async analyzeTranscript(transcript) {
        if (!this.llmClient)
            throw new Error("LLM client not initialized");
        const systemPrompt = `Jeste≈õ ekspertem analizy sesji rad miejskich/gminnych w Polsce. Twoim zadaniem jest podzieliƒá transkrypcjƒô na wypowiedzi poszczeg√≥lnych m√≥wc√≥w.

## ZASADY IDENTYFIKACJI M√ìWC√ìW:

1. **PrzewodniczƒÖcy Rady** - prowadzi obrady, udziela g≈Çosu, zarzƒÖdza g≈Çosowania, m√≥wi "proszƒô o g≈Ços", "przechodzimy do punktu", "otwieram dyskusjƒô", "zarzƒÖdzam g≈Çosowanie"

2. **Burmistrz/W√≥jt** - przedstawia projekty uchwa≈Ç, odpowiada na pytania radnych, referuje sprawy gminy, u≈ºywa zwrot√≥w "szanowni pa≈Ñstwo radni", "w imieniu urzƒôdu"

3. **Skarbnik** - omawia sprawy finansowe, bud≈ºet, podatki, u≈ºywa terminologii finansowej

4. **Sekretarz** - odczytuje protoko≈Çy, sprawdza kworum, potwierdza wyniki g≈Çosowa≈Ñ

5. **Radni** - zadajƒÖ pytania, sk≈ÇadajƒÖ wnioski, dyskutujƒÖ, g≈ÇosujƒÖ. Numeruj ich: "Radny 1", "Radny 2" itd. Je≈õli radny siƒô przedstawia ("Jan Kowalski") lub jest wymieniony z nazwiska, u≈ºyj "Radny Kowalski"

6. **Mieszka≈Ñcy/Go≈õcie** - wypowiadajƒÖ siƒô w punkcie "wolne wnioski" lub sƒÖ zaproszeni, oznacz jako "Mieszkaniec" lub "Go≈õƒá"

## WSKAZ√ìWKI ROZPOZNAWANIA ZMIANY M√ìWCY:

- Zmiana tematu wypowiedzi
- Zwroty typu "dziƒôkujƒô", "proszƒô bardzo", "kto nastƒôpny"
- Pytania i odpowiedzi (dwa r√≥≈ºne m√≥wcy)
- Zmiana stylu/tonu wypowiedzi
- Odniesienia do poprzedniego m√≥wcy ("zgadzam siƒô z przedm√≥wcƒÖ")

## FORMAT WYPOWIEDZI:

Ka≈ºda wypowied≈∫ powinna byƒá osobnym segmentem. PODZIEL tekst na MINIMUM 10-20 segment√≥w dla d≈Çu≈ºszych transkrypcji.

Odpowiedz TYLKO w formacie JSON:
{
  "segments": [
    {
      "timestamp": "00:00:00",
      "speaker": "PrzewodniczƒÖcy",
      "text": "Otwieram XXIII sesjƒô Rady Miejskiej. Stwierdzam kworum.",
      "sentiment": "neutral",
      "emotion": "spok√≥j",
      "emotionEmoji": "üôÇ",
      "tension": 2,
      "credibility": 95,
      "credibilityEmoji": "‚úÖ"
    },
    {
      "timestamp": "00:01:30",
      "speaker": "Radny 1",
      "text": "Mam pytanie dotyczƒÖce bud≈ºetu...",
      "sentiment": "neutral",
      "emotion": "zainteresowanie",
      "emotionEmoji": "ü§î",
      "tension": 3,
      "credibility": 90,
      "credibilityEmoji": "‚úÖ"
    }
  ],
  "summary": {
    "averageTension": 3.5,
    "dominantSentiment": "neutral",
    "overallCredibility": 85,
    "overallCredibilityEmoji": "üü¢",
    "speakerCount": 8,
    "duration": "1:32:00"
  }
}`;
        const response = await this.llmClient.chat.completions.create({
            model: this.llmModel,
            messages: [
                { role: "system", content: systemPrompt },
                {
                    role: "user",
                    content: `Przeanalizuj transkrypcjƒô sesji rady i podziel na wypowiedzi m√≥wc√≥w:\n\n${transcript.slice(0, 25000)}`,
                },
            ],
            temperature: 0.2,
            response_format: { type: "json_object" },
            max_tokens: 8000,
        });
        const content = response.choices[0]?.message?.content;
        if (!content) {
            throw new Error("Brak odpowiedzi od GPT-4");
        }
        try {
            return JSON.parse(content);
        }
        catch {
            return {
                segments: [
                    {
                        timestamp: "00:00:00",
                        speaker: "M√≥wca",
                        text: transcript,
                        sentiment: "neutral",
                        emotion: "neutralny",
                        emotionEmoji: "üòê",
                        tension: 5,
                        credibility: 50,
                        credibilityEmoji: "üü°",
                    },
                ],
                summary: {
                    averageTension: 5,
                    dominantSentiment: "neutral",
                    overallCredibility: 50,
                    overallCredibilityEmoji: "üü°",
                    speakerCount: 1,
                    duration: "0:00",
                },
            };
        }
    }
    formatTranscriptMarkdown(correctedTranscript, segments, summary, videoTitle, videoUrl) {
        const date = new Date().toLocaleDateString("pl-PL", {
            year: "numeric",
            month: "long",
            day: "numeric",
            hour: "2-digit",
            minute: "2-digit",
        });
        let md = `# Transkrypcja Sesji Rady\n\n`;
        md += `**Tytu≈Ç:** ${videoTitle}\n\n`;
        md += `**≈πr√≥d≈Ço:** [YouTube](${videoUrl})\n\n`;
        md += `**Data transkrypcji:** ${date}\n\n`;
        md += `---\n\n`;
        md += `## Podsumowanie\n\n`;
        md += `| Parametr | Warto≈õƒá |\n`;
        md += `|----------|--------|\n`;
        md += `| Czas trwania | ${summary.duration} |\n`;
        md += `| Liczba m√≥wc√≥w | ${summary.speakerCount} |\n`;
        md += `| ≈örednie napiƒôcie | ${summary.averageTension?.toFixed(1) || "N/A"}/10 |\n`;
        md += `| DominujƒÖcy sentyment | ${summary.dominantSentiment} |\n`;
        md += `| Og√≥lna wiarygodno≈õƒá | ${summary.overallCredibility}% ${summary.overallCredibilityEmoji} |\n\n`;
        md += `---\n\n`;
        md += `## Pe≈Çna transkrypcja\n\n`;
        md += `${correctedTranscript}\n\n`;
        md += `---\n\n`;
        md += `## Analiza wypowiedzi\n\n`;
        for (const seg of segments) {
            md += `### ${seg.speaker}\n\n`;
            md += `> ${seg.text}\n\n`;
            md += `- **Sentyment:** ${seg.sentiment} ${seg.emotionEmoji}\n`;
            md += `- **Emocja:** ${seg.emotion}\n`;
            md += `- **Napiƒôcie:** ${seg.tension}/10\n`;
            md += `- **Wiarygodno≈õƒá:** ${seg.credibility}% ${seg.credibilityEmoji}\n\n`;
        }
        md += `---\n\n`;
        md += `*Dokument wygenerowany automatycznie przez Asystent Radnego*\n`;
        return md;
    }
}
//# sourceMappingURL=youtube-downloader.js.map