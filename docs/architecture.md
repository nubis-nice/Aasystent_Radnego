# Architektura: Asystent Radnego (Gmina Drawno)

## 1. Cel systemu

System automatyzuje obieg dokument√≥w Rady Miejskiej (pozyskanie, ekstrakcja tre≈õci multimodalnym LLM, analiza, wyszukiwanie) i udostƒôpnia Radnemu panel/czat do pracy z materia≈Çami wraz z cytatami oraz sygna≈Çami ryzyk.

## 2. Za≈Ço≈ºenia niefunkcjonalne (inwarianty)

- **Deterministyczno≈õƒá**: domy≈õlnie `temperature=0`, wersjonowanie prompt√≥w.
- **Kontrakty danych**: wszystkie wej≈õcia/wyj≈õcia walidowane (Zod), wersjonowane (`v1`).
- **Fail fast**: b≈ÇƒÖd, gdy brak tekstu po ekstrakcji / brak metadanych krytycznych / uszkodzony plik.
- **Obserwowalno≈õƒá**: logi JSON z `traceId`, czasy etap√≥w, statusy job√≥w.
- **Bezpiecze≈Ñstwo**: klucze API tylko w zmiennych ≈õrodowiskowych; brak danych wra≈ºliwych w logach.

## 3. Stos technologiczny (docelowo)

## 3.1. Repozytorium (monorepo)

Projekt jest utrzymywany jako monorepo (**npm workspaces**) z osobnymi aplikacjami uruchomieniowymi w `apps/*` (frontend/api/worker) oraz wsp√≥≈Çdzielonym kodem w `packages/*`.

- **Runtime**: Node.js LTS
- **Jƒôzyk**: TypeScript
- **Backend**: Fastify (lub NestJS + Fastify)
- **Kolejka**: BullMQ + Redis
- **DB**: PostgreSQL + pgvector
- **Ekstrakcja tre≈õci z dokument√≥w/skan√≥w**: multimodalny LLM (OpenAI)
- **LLM**: OpenAI + tool calling
- **UI**: panel webowy (np. Next.js) + czat

## 4. Modu≈Çy i odpowiedzialno≈õci

### 4.0. System ≈∫r√≥de≈Ç danych (Data Sources) - Agent Winsdurf

**Za≈Ço≈ºenia strategiczne:**
Agent AI "Winsdurf" oparty na aktualnych, zewnƒôtrznych ≈∫r√≥d≈Çach prawa zamiast lokalnego kontekstu MCP.

**Architektura API-first:**

**WARSTWA 1 - ≈πr√≥d≈Ça danych (API / scraping):**

- ISAP (Sejm RP) - HTML/XML scraping
- RCL - akty wykonawcze
- WSA/NSA - orzecznictwo (scraping)
- RIO - uchwa≈Çy i rozstrzygniƒôcia nadzorcze (scraping)
- BIP JST - scraping
- Dzienniki Urzƒôdowe Wojew√≥dztw - scraping

**WARSTWA 2 - Adaptery pobierania:**

- `BaseDataFetcher` - bazowa klasa
- `ApiDataFetcher` - uniwersalny klient API (OAuth2, API key, Basic, Bearer)
- `ScraperDataFetcher` - web scraping z Cheerio
- `UnifiedDataService` - orkiestrator ≈ÇƒÖczƒÖcy API i scraping

**WARSTWA 3 - Silniki analityczne:**

- Legal Search API - wyszukiwanie prawne (fulltext + semantic)
- Legal Reasoning Engine - analiza prawna z ryzykami
- Budget Analysis Engine - analiza bud≈ºetowa i wykrywanie anomalii

**Typy ≈∫r√≥de≈Ç:**

- `api_isap`, `api_rcl`, `api_wsa_nsa`, `api_rio` - ≈∫r√≥d≈Ça prawne
- `scraper_bip`, `scraper_dziennik`, `scraper_custom` - scraping
- `api_custom` - niestandardowe API

**Metody pobierania:**

- `api` - REST API z konfiguracjƒÖ (auth, pagination, response mapping)
- `scraping` - web scraping z selektorami CSS
- `hybrid` - kombinacja API i scrapingu

### 4.0.1. Inteligentny Scraping z AI (2026-01-14)

**Zasada:** Wszystkie dane strukturalne (daty, miejsca, encje) sƒÖ wyodrƒôbniane przez AI, nie przez regex.

**Przep≈Çyw danych:**

```text
IntelligentScraper.analyzeContentWithLLM()
  ‚îî‚îÄ extractedDates, extractedEntities, keyTopics, summary
     ‚îî‚îÄ metadata.llmAnalysis w scraped_content
        ‚îî‚îÄ processToRAG() ‚Üí processed_documents.metadata
           ‚îú‚îÄ Frontend: FormattedDocumentContent (wy≈õwietla dane AI)
           ‚îî‚îÄ calendar-auto-import (importuje tylko z danych AI)
```

**Struktura `metadata.llmAnalysis`:**

- `relevanceScore` (0-100) - ocena przydatno≈õci dla radnego
- `contentType` - typ tre≈õci (sesja/kalendarz/uchwa≈Ça/protok√≥≈Ç)
- `summary` - kr√≥tkie podsumowanie
- `keyTopics` - kluczowe tematy
- `extractedDates` - daty wyodrƒôbnione z tre≈õci
- `extractedEntities` - encje (miejsca, osoby, komisje)
- `isRelevantForCouncilor` - flaga przydatno≈õci
- `recommendedAction` - scrape/skip/priority

**Korzy≈õci:**

- Jedno ≈∫r√≥d≈Ço prawdy dla dat/miejsc sesji
- Sp√≥jno≈õƒá miƒôdzy widokiem dokumentu a kalendarzem
- AI rozumie kontekst lepiej ni≈º regex

### 4.1. Ingest (pobieranie)

- Pobiera dokumenty z zewnƒôtrznych ≈∫r√≥de≈Ç przez `UnifiedDataService`.
- Deduplikacja: `hash` tre≈õci + URL.
- Zapis surowych danych w `scraped_content`.

### 4.2. Normalizer

- Identyfikuje format (PDF/DOCX/skan).
- Konwersja do formatu roboczego (je≈õli potrzebne).

### 4.3. Ekstrakcja tre≈õci (multimodal)

- Ekstrakcja tekstu i struktury z PDF/skan√≥w przez multimodalny LLM.
- `qualityScore` + walidacja minimalnej jako≈õci.

### 4.4. Metadane

- Tytu≈Ç, numer, data, autor, temat/tags.
- ≈πr√≥d≈Ço i identyfikatory.
- **Hierarchia Wa≈ºno≈õci** (1-5):
  - Poziom 1: Akty prawne, bud≈ºet (100-90 pkt)
  - Poziom 2: Protoko≈Çy, transkrypcje (89-70 pkt)
  - Poziom 3: Opinie, analizy (69-50 pkt)
  - Poziom 4: Administracyjne (49-30 pkt)
  - Poziom 5: Za≈ÇƒÖczniki, t≈Ço (<30 pkt)
  - Szczeg√≥≈Çy: `docs/document_hierarchy.md`

### 4.5. Index/RAG

- Chunking + embedding (OpenAI embedding).
- Przechowywanie wektor√≥w w pgvector.

### 4.6. Analizy

- Streszczenie, kluczowe punkty.
- PowiƒÖzania uchwa≈Ç.
- Skan ryzyk (MVP: heurystyki + cytaty).

### 4.7. Transkrypcja sesji rady (audio/wideo)

- Pobranie/za≈Çadowanie nagra≈Ñ sesji rady.
- Transkrypcja (ASR) w OpenAI Whisper + segmentacja czasowa.
- Indeksowanie transkryptu do wyszukiwania i Q&A.

### 4.7.1. Zaawansowana Transkrypcja z AnalizƒÖ (2026-01-10)

**Obs≈Çugiwane formaty:** MP3, WAV, OGG, M4A, FLAC, AAC, MP4, WebM, MKV, AVI, MOV

**Funkcje:**

- **Transkrypcja Whisper** - rozpoznawanie mowy z timestampami
- **Identyfikacja rozm√≥wc√≥w** - Speaker 1, 2, 3... na podstawie kontekstu
- **Analiza sentymentu** - pozytywny/neutralny/negatywny dla ka≈ºdej wypowiedzi
- **Emocje** - rozpoznawanie emocji (üòäüò¢üò†üò®ü§î)
- **Napiƒôcie emocjonalne** - skala 1-10
- **Detekcja wiarygodno≈õci** - analiza lingwistyczna k≈Çamstwa (% + emoji)

**Wska≈∫niki wiarygodno≈õci:**

- 90-100% ‚úÖ - Wysoka wiarygodno≈õƒá
- 70-89% üü¢ - Prawdopodobnie prawda
- 50-69% üü° - Niepewne
- 30-49% ‚ö†Ô∏è - Podejrzane
- 0-29% üî¥ - Niska wiarygodno≈õƒá

**Analiza bazuje na:**

- Sp√≥jno≈õƒá wypowiedzi
- Wahania, zmiany zdania
- Nadmierne szczeg√≥≈Çy lub ich brak
- Unikanie odpowiedzi
- Kontekst lingwistyczny

### 4.8. Scenopisy sesji rady

- Generowanie scenopisu na bazie transkryptu (agenda -> tematy -> wypowiedzi -> wnioski/decyzje).
- Wersje: kr√≥tkie podsumowanie oraz szczeg√≥≈Çowy przebieg.

### 4.9. UI / Chat / Dashboard

- Lista dokument√≥w i analiz.
- Q&A z cytatami.
- Raporty okresowe.
- **Dashboard**: nag≈Ç√≥wek ≈ÇƒÖczy tytu≈Ç sekcji z kartami statystyk (dokumenty, konwersacje, zapytania AI, aktywno≈õƒá tygodnia) w jednym komponencie z gradientowym t≈Çem.
- **Kalendarz**: widget wspiera tryby miesiƒÖc/tydzie≈Ñ; widok tygodniowy ma 7 kolumn z sekcjƒÖ wydarze≈Ñ ca≈Çodziennych i blokami 6‚Äëgodzinnymi przewijanymi bez widocznych pask√≥w.

## 5. Tool calling (narzƒôdzia LLM)

LLM wywo≈Çuje narzƒôdzia aplikacyjne zamiast ‚Äûwymy≈õlaƒá‚Äù wyniki. Ka≈ºde narzƒôdzie:

- ma schemat wej≈õcia/wyj≈õcia (Zod), wersjƒô (`v1`),
- loguje `traceId`,
- zwraca dane do cytowania.

Minimalny zestaw (MVP):

- `search_documents`
- `get_document`
- `get_document_citations`
- `summarize_document`
- `qa_over_documents`
- `find_related_resolutions`
- `generate_weekly_report`
- `generate_session_brief`
- `legal_risk_scan`
- `transcribe_session_recording`
- `generate_session_screenplay`

## 6. Model danych (skr√≥t)

- `Document`, `DocumentVersion`, `ExtractedText`, `Metadata`, `Chunk`, `Analysis`, `Recording`, `Transcript`, `Screenplay`

## 7. Konfiguracja Provider√≥w AI (2026-01-11)

### 7.1 Architektura Multi-Provider

System obs≈Çuguje wielu provider√≥w AI z podzia≈Çem na **5 niezale≈ºnych funkcji**:

| Funkcja        | Opis                   | Przyk≈Çadowe providery          |
| -------------- | ---------------------- | ------------------------------ |
| **LLM**        | Modele jƒôzykowe (chat) | OpenAI, Ollama, Anthropic      |
| **Embeddings** | Wektory semantyczne    | OpenAI, Ollama                 |
| **Vision**     | Analiza obraz√≥w        | OpenAI GPT-4V, Ollama LLaVA    |
| **STT**        | Speech-to-Text         | OpenAI Whisper, faster-whisper |
| **TTS**        | Text-to-Speech         | OpenAI TTS, Piper              |

### 7.2 Presety Konfiguracji

- **OpenAI** - pe≈Çna konfiguracja OpenAI API
- **Ollama (Local)** - lokalne modele + faster-whisper-server dla STT
- **Custom** - dowolny endpoint z wyborem protoko≈Çu API

### 7.3 Struktura Kodu

```text
apps/api/src/ai/
‚îú‚îÄ‚îÄ index.ts                    # Eksport publiczny
‚îú‚îÄ‚îÄ defaults.ts                 # Presety konfiguracji
‚îú‚îÄ‚îÄ types.ts                    # Typy i interfejsy
‚îú‚îÄ‚îÄ ai-config-resolver.ts       # Resolver konfiguracji z cache
‚îú‚îÄ‚îÄ ai-client-factory.ts        # Fabryka klient√≥w AI
‚îî‚îÄ‚îÄ clients/
    ‚îú‚îÄ‚îÄ llm-client.ts           # Klient LLM
    ‚îú‚îÄ‚îÄ embeddings-client.ts    # Klient embedding√≥w
    ‚îú‚îÄ‚îÄ vision-client.ts        # Klient vision
    ‚îú‚îÄ‚îÄ stt-client.ts           # Klient STT
    ‚îî‚îÄ‚îÄ tts-client.ts           # Klient TTS
```

### 7.4 Baza Danych

- `ai_configurations` - g≈Ç√≥wna konfiguracja u≈ºytkownika (preset, is_default)
- `ai_providers` - konfiguracja ka≈ºdej funkcji AI (LLM, Embeddings, Vision, STT, TTS)

### 7.5 Zmienne ≈örodowiskowe (fallback)

- `OPENAI_API_KEY` (w `.env`, nie commitowaƒá)
- `OPENAI_MODEL`
- `OPENAI_EMBEDDING_MODEL`
- opcjonalnie: `OPENAI_BASE_URL`, `OPENAI_ORG_ID`, `OPENAI_PROJECT_ID`

Szczeg√≥≈Çy: `.windsurf/base_rules.md` (zasady budowania aplikacji)

## 8. Granice odpowiedzialno≈õci

- System dostarcza **wsparcie analityczne** i sygna≈Çy ryzyk; nie zastƒôpuje opinii prawnej.

---

## 9. Observability & DevOps (2026-01-14)

- **TraceId everywhere** ‚Äì API i worker logujƒÖ `traceId`, nazwƒô narzƒôdzia (`tool=deep_research`, `tool=rag_search`, `tool=session_discovery`), czas trwania i status. B≈Çƒôdy HTTP zawsze zwracajƒÖ `errorId` = `traceId`.
- **Monitoring pipeline‚Äôu** ‚Äì BullMQ publikuje metryki job√≥w (czas start/stop, retry, failure_reason) do Redis/Prometheus. Dashboard operacyjny ≈õledzi: liczbƒô dokument√≥w w ingest, b≈Çƒôdy OCR, b≈Çƒôdy DeepResearch, rozmiar kolejek.
- **Konfiguracja ≈õrodowisk** ‚Äì osobne `.env` dla `apps/api`, `apps/frontend`, `apps/worker`. Sekrety zarzƒÖdzamy poza repo (Doppler/1Password). `api_configurations` przechowuje zaszyfrowane klucze provider√≥w i deterministycznie kontroluje, kt√≥rzy providerzy sƒÖ aktywni.
- **Release checklist** ‚Äì lint + type-check, smoke test `/health`, test zapytania RAG, test DeepResearch (mock provider). Deployment lokalny: `npm run dev`; produkcyjny: docker-compose profile `api`, `frontend`, `worker`.
- **Alerty operacyjne** ‚Äì brak dostƒôpu do Supabase, b≈Çƒôdy 5xx dla `/api/research`, kolejka BullMQ > 50 job√≥w, brak nowych dokument√≥w >24h. Alerty trafiajƒÖ do kana≈Çu #windsurf-ops oraz do w≈Ça≈õciciela zmiany.

## Stan implementacji (2026-01-09)

### Co dzia≈Ça (deployment local dev)

- **Infrastruktura**: Docker Compose (Redis, Whisper) + Supabase PostgreSQL (cloud).
- **Frontend**: Next.js (app router) na `localhost:3000` ‚Äî kompletny panel z nawigacjƒÖ.
- **API**: Fastify na `localhost:3001` ‚Äî pe≈Çne API (dokumenty, analizy, czat, research).
- **Worker**: BullMQ + Redis ‚Äî joby ekstrakcji, analizy, wykrywania relacji.
- **Repo**: npm workspaces (apps/api, apps/frontend, apps/worker, packages/shared).

### Zaimplementowane modu≈Çy

- **API Routes** (10 plik√≥w):

  - `auth.ts` - autoryzacja Supabase
  - `chat.ts` - czat AI z RAG
  - `data-sources.ts` - zarzƒÖdzanie ≈∫r√≥d≈Çami danych
  - `deep-research.ts` - Deep Internet Researcher
  - `documents.ts` - CRUD dokument√≥w
  - `legal-analysis.ts` - analizy prawne
  - `providers.ts` - konfiguracja provider√≥w AI
  - `api-models.ts` - modele AI
  - `test-api.ts`, `test.ts` - testowanie

- **Services** (silniki analityczne):

  - `legal-search-api.ts` - wyszukiwanie fulltext/semantic/hybrid
  - `legal-reasoning-engine.ts` - analiza prawna z ryzykami
  - `budget-analysis-engine.ts` - analiza bud≈ºetowa
  - `deep-research-service.ts` - multi-provider research
  - `unified-data-service.ts` - orkiestrator pobierania danych
  - `scraper-v2.ts` - web scraping z Cheerio
  - `semantic-document-discovery.ts` - semantic search z intelligent scraping
  - `document-analysis-service.ts` - analiza dokument√≥w z crawlingiem ≈∫r√≥de≈Ç
  - `intelligent-scraper.ts` - zaawansowany scraper z LLM analysis
  - `context-compressor.ts` - kompresja kontekstu AI (tokenizer, summaryzacja)
  - `batch-embedding-service.ts` - OpenAI Batch API dla embedding√≥w (50% taniej)
  - `document-processor.ts` - przetwarzanie PDF/DOCX z OCR (Tesseract.js + Sharp)
  - `document-query-service.ts` - inteligentne wykrywanie dokument√≥w w chacie (ID/nazwa ‚Üí RAG ‚Üí potwierdzenie)

- **Data Fetchers**:

  - `api-fetcher.ts` - klient API (OAuth2, API key, Basic, Bearer)
  - `scraper-fetcher.ts` - web scraping
  - `base-fetcher.ts` - bazowa klasa

- **Research Providers** (z automatycznym fallback gdy provider zawiedzie):

  - `exa-provider.ts` - Exa AI (priorytet 1)
  - `brave-provider.ts` - Brave Search (priorytet 2, dobre wsparcie PL)
  - `tavily-provider.ts` - Tavily AI (priorytet 2)
  - `serper-provider.ts` - Serper/Google (priorytet 3)

- **Worker Jobs**:

  - `extraction.ts` - ekstrakcja tekstu z PDF/skan√≥w
  - `analysis.ts` - streszczenie + skanowanie ryzyk
  - `relations.ts` - wykrywanie relacji miƒôdzy dokumentami

- **Frontend Pages**:

  - `/dashboard` - panel g≈Ç√≥wny
  - `/documents` - lista i podglƒÖd dokument√≥w
  - `/chat` - czat AI z cytatami
  - `/analysis` - analizy prawne i bud≈ºetowe
  - `/research` - Deep Internet Researcher
  - `/settings/*` - ustawienia (profil, API, ≈∫r√≥d≈Ça danych, wyglƒÖd)
  - `/admin/users` - zarzƒÖdzanie u≈ºytkownikami

- **Migracje bazy danych** (17 plik√≥w SQL):
  - Schematy: users, documents, chunks, analyses, conversations, data_sources, research_reports
  - Funkcje: semantic search, embedding matching

### Do uruchomienia (wymagane)

- Uruchomienie wszystkich migracji w Supabase
- Konfiguracja zmiennych ≈õrodowiskowych (OPENAI*API_KEY, SUPABASE*\*)
- Test z prawdziwymi dokumentami
